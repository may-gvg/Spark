{"cells":[{"cell_type":"code","source":["sc"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7acd079a-1a69-424b-8076-b78ab9b08e33"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"\n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=337306706333968#setting/sparkui/1122-074139-mjjo82c4/driver-1851273262017137892\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.1.2</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        ","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["\n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=337306706333968#setting/sparkui/1122-074139-mjjo82c4/driver-1851273262017137892\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.1.2</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        "]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["pip install -Iv tweepy==3.10.0\n\npip install textblob"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"133f5843-e9e8-452b-96e3-2fda739c8308"}}},{"cell_type":"code","source":["import json\nimport socket\nimport tweepy\nfrom tweepy import OAuthHandler\nfrom tweepy import Stream\nfrom tweepy.streaming import StreamListener\n\n\nclass TweetsListener(StreamListener):\n    # tweet object listens for the tweets\n    def __init__(self, csocket):\n        self.client_socket = csocket\n\n    def on_data(self, data):\n\n        try:\n            msg = json.loads(data)\n            print(\"new message\")\n            # if tweet is longer than 140 characters\n            if \"extended_tweet\" in msg:\n                # add at the end of each tweet \"t_end\"\n                self.client_socket \\\n                    .send(str(msg['extended_tweet']['full_text'] + \"t_end\") \\\n                          .encode('utf-8'))\n                print(msg['extended_tweet']['full_text'])\n            else:\n                # add at the end of each tweet \"t_end\"\n                self.client_socket \\\n                    .send(str(msg['text'] + \"t_end\") \\\n                          .encode('utf-8'))\n                print(msg['text'])\n            return True\n        except BaseException as e:\n            print(\"Error on_data: %s\" % str(e))\n        return True\n\n    def on_error(self, status):\n        print(status)\n        return True\n\n\ndef sendData(c_socket, keyword):\n    consumer_key = '8xZjcoaxuVJ84lX10LQYVN9q8'\n    consumer_secret = 'S6AhI46bG7CrJZ4a49EzXYnfbqnSmXFfuM2FGDfb6lziCihVfc'\n    access_token = '1462005344071266306-Av1AALQFaKRAaL2xDTEtg8mXCO7mNS'\n    access_secret = 'fL82WS7zBnVxU2YA9OJdAoaVaOF71Zc2FyBItBLm3KchD'\n\n    print('start sending data from Twitter to socket')\n    # authentication based on the credentials\n    auth = OAuthHandler(consumer_key, consumer_secret)\n    auth.set_access_token(access_token, access_secret)\n    # start sending data from the Streaming API\n    twitter_stream = Stream(auth, TweetsListener(c_socket))\n    twitter_stream.filter(track=keyword, languages=[\"en\"])\n\n\nif __name__ == \"__main__\":\n    # server (local machine) creates listening socket\n    s = socket.socket()\n    host = \"127.0.0.1\"\n    port = 5556\n    s.bind((host, port))\n    print('socket is ready')\n    # server (local machine) listens for connections\n    s.listen(4)\n    print('socket is listening')\n    # return the socket and the address on the other side of the connection (client side)\n    c_socket, addr = s.accept()\n    print(\"Received request from: \" + str(addr))\n    # select here the keyword for the tweet data\n    sendData(c_socket, keyword=['piano'])\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"91f03775-3113-462b-8b3e-f187095a54fe"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"socket is ready\nsocket is listening\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["socket is ready\nsocket is listening\n"]},"transient":null},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Cancelled","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql import SparkSession\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import *\nimport pyspark\nfrom textblob import TextBlob\n\n\ndef preprocessing(lines):\n    words = lines.select(explode(split(lines.value, \"t_end\")).alias(\"word\"))\n    words = words.na.replace('', None)\n    words = words.na.drop()\n    words = words.withColumn('word', F.regexp_replace('word', r'http\\S+', ''))\n    words = words.withColumn('word', F.regexp_replace('word', '@\\w+', ''))\n    words = words.withColumn('word', F.regexp_replace('word', '#', ''))\n    words = words.withColumn('word', F.regexp_replace('word', 'RT', ''))\n    words = words.withColumn('word', F.regexp_replace('word', ':', ''))\n    return words\n\n\n# text classification\ndef polarity_detection(text):\n    return TextBlob(text).sentiment.polarity\n\n\ndef subjectivity_detection(text):\n    return TextBlob(text).sentiment.subjectivity\n\n\ndef text_classification(words):\n    # polarity detection\n    polarity_detection_udf = udf(polarity_detection, StringType())\n    words = words.withColumn(\"polarity\", polarity_detection_udf(\"word\"))\n    # subjectivity detection\n    subjectivity_detection_udf = udf(subjectivity_detection, StringType())\n    words = words.withColumn(\"subjectivity\", subjectivity_detection_udf(\"word\"))\n    return words\n\n\nif __name__ == \"__main__\":\n    # create Spark session\n    spark = SparkSession.builder.appName(\"TwitterSentimentAnalysis\").config(\"spark.executor.heartbeatInterval\",\"3600s\").config(\"spark.network.timeout\", \"3601s\").config(\"spark.files.fetchTimeout\", \"3600s\").getOrCreate()\n\n\n    # read the tweet data from socket\n    lines = spark.readStream.format(\"socket\").option(\"host\", \"127.0.0.1\").option(\"port\", 5556).option(\"soTimeout\", 20000).load()\n    # Preprocess the data\n    words = preprocessing(lines)\n    # text classification to define polarity and subjectivity\n    words = text_classification(words)\n\n    words = words.repartition(1)\n    query = words.writeStream.queryName(\"all_tweets\") \\\n        .outputMode(\"append\").format(\"parquet\") \\\n        .option(\"path\", \"dbfs:/\") \\\n        .option(\"checkpointLocation\", \"dbfs:/\") \\\n        .trigger(processingTime='60 seconds').start()\n    query.awaitTermination()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2fcf5d47-5d8e-4870-bd4b-f26cb715332e"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%fs ls \n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f770154a-e912-49b8-91ec-bd71d59e1fcf"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Cancelled","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"27702e56-977e-4785-bb87-52facdc41586"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df = spark.read.parquet('dbfs:/part-00000-02de3ac4-c4a7-4514-8c83-a892a8d00b52-c000.snappy.parquet')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4df604e2-e730-453d-9b94-51f8c93e3855"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"415c8e09-18f9-43f3-a175-467f9b3c0235"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bce0106f-4e92-4152-8a13-87d9209114b0"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"sentimental","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":4313460803975308}},"nbformat":4,"nbformat_minor":0}
